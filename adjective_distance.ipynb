{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RT @Always_Trump: BOMBSHELL:  Clinton Campaign...\n",
       "1    RT @c5hardtop1999: Hillary's foreign policy ha...\n",
       "2    If she wins, be aware that the one who warms y...\n",
       "3    RT @wikileaks: Bernie Sanders wife Jane Sander...\n",
       "4    RT @wikileaks: Bernie Sanders wife Jane Sander...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data frame\n",
    "#df = pd.read_csv('/media/zainkhan/USB30FD/suspended-trump-tweets.txt', encoding='latin1', error_bad_lines=False, warn_bad_lines=False, header=None)\n",
    "df = pd.read_csv('/media/zainkhan/My Passport/15Days/22-7Clinton.txt', sep=\"\\n\", encoding='latin1', error_bad_lines=False, warn_bad_lines=False, header=None)\n",
    "df = df[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [rt, @always_trump:, bombshell:, clinton, camp...\n",
       "1    [rt, @c5hardtop1999:, hillary's, foreign, poli...\n",
       "2    [if, she, wins,, be, aware, that, the, one, wh...\n",
       "3    [rt, @wikileaks:, bernie, sanders, wife, jane,...\n",
       "4    [rt, @wikileaks:, bernie, sanders, wife, jane,...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "df = df.str.lower().str.split()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [rt, @always_trump:, bombshell:, clinton, camp...\n",
       "1    [rt, @c5hardtop1999:, hillary's, foreign, poli...\n",
       "2    [wins,, aware, one, warms, bed, may, involunta...\n",
       "3    [rt, @wikileaks:, bernie, sanders, wife, jane,...\n",
       "4    [rt, @wikileaks:, bernie, sanders, wife, jane,...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = nltk.corpus.stopwords.words('english')\n",
    "df = df.dropna().apply(lambda x: [item for item in x if item not in stop])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['rt', '@always_trump:', 'bombshell:', 'clinton', 'campaign', 'admits', 'globalization', 'hurts', 'wages', '&amp;', 'jobs!', 'want', 'it,', 'hillary?', '#podestaemails'], ['rt', '@c5hardtop1999:', \"hillary's\", 'foreign', 'policy', 'consisted', 'selling', 'access', 'clinton', 'foundation', '&amp;', 'promoting', 'muslim', 'brotherho']]\n"
     ]
    }
   ],
   "source": [
    "# Separate into sentences\n",
    "sentences = df.tolist()\n",
    "print(sentences[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bombshell', 'clinton', 'campaign', 'admits', 'globalization', 'hurts', 'wages', 'jobs', 'want', 'hillary'], ['hillary', 'foreign', 'policy', 'consisted', 'selling', 'access', 'clinton', 'foundation', 'promoting', 'muslim', 'brotherho']]\n"
     ]
    }
   ],
   "source": [
    "# Clean and remove illegal characters\n",
    "import re\n",
    "def clean(s):\n",
    "    for i, w in enumerate(s):\n",
    "        if contains_illegal(w):\n",
    "            s[i] = ''\n",
    "        else:\n",
    "            if 'cli' in w:\n",
    "                s[i] = 'clinton'\n",
    "            elif 'hrc' in w or 'hil' in w:\n",
    "                s[i] = 'hillary'\n",
    "            elif 'tru' in w or 'trmp' in w:\n",
    "                s[i] = 'trump'\n",
    "            elif 'bern' in w:\n",
    "                s[i] = 'bernie'\n",
    "            elif 'sander' in w:\n",
    "                s[i] = 'sanders'\n",
    "            extras = '0123456789~_=*^,.-`%\"\"+#&\"!?<>:;/\\\\\\'()[]{}$|\\x91\\x92\\x93\\x94\\x96\\x97'\n",
    "            s[i] = s[i].translate({ord(c):'' for c in extras})\n",
    "            if len(s[i]) < 4:\n",
    "                s[i] = ''\n",
    "    return s\n",
    "                    \n",
    "def contains_illegal(w):\n",
    "    illegal = ['@', '#', 'htt', 'via', 'desd']\n",
    "    if any(x in w for x in illegal):\n",
    "        return True\n",
    "    if re.match(\"1\", w) is not None:\n",
    "        return True\n",
    "    return False \n",
    "\n",
    "sentences = [clean(s) for s in sentences if len(s) > 0]\n",
    "sentences = [list(filter(None, sentence)) for sentence in sentences]\n",
    "print(sentences[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accessible', 'active', 'adaptable', 'admirable', 'adventurous']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get adjective list to iterate over\n",
    "adj = pd.read_csv('adjectives-character-richards.csv')\n",
    "adj = adj.values.tolist()\n",
    "adj = [word[0] for word in adj]\n",
    "adj.append('corrupt')\n",
    "adj.append('crooked')\n",
    "adj[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps adjective occurences per sentence relative to a word\n",
    "def adj_to_word(sentences, adj_list, target):\n",
    "    adj_to_word = {}\n",
    "    sentences_with_target = [s for s in sentences if target in s]\n",
    "\n",
    "    for adj in adj_list:\n",
    "        for sentence in sentences_with_target:\n",
    "            if adj in sentence:\n",
    "                if adj in adj_to_word:\n",
    "                    adj_to_word[adj] += 1\n",
    "                else:\n",
    "                    adj_to_word[adj] = 1\n",
    "    return adj_to_word\n",
    "\n",
    "target_word = 'clinton'\n",
    "d = adj_to_word(sentences, adj, target_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['criminal', 98915], ['crooked', 73512], ['private', 61983]]\n"
     ]
    }
   ],
   "source": [
    "dlist = []\n",
    "for key, value in d.items():\n",
    "    temp = [key,value]\n",
    "    dlist.append(temp)\n",
    "dlist.sort(key=lambda x: x[1], reverse=True)\n",
    "print(dlist[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clinton\n",
      "criminal 98915\n",
      "crooked 73512\n",
      "private 61983\n",
      "corrupt 44597\n",
      "ignorant 34424\n",
      "political 29481\n",
      "open 19697\n",
      "stupid 14368\n",
      "sober 13002\n",
      "honest 12161\n",
      "false 11791\n",
      "cold 11183\n",
      "winning 11161\n",
      "loyal 9857\n",
      "confident 9542\n",
      "alert 8676\n",
      "strong 8092\n",
      "liberal 7883\n",
      "deep 7630\n",
      "quiet 7618\n",
      "clean 7187\n",
      "friendly 7171\n",
      "dirty 6964\n",
      "transparent 6471\n",
      "ordinary 6458\n",
      "desperate 6190\n",
      "responsible 5873\n",
      "serious 5860\n",
      "clever 5702\n",
      "secure 5521\n",
      "conservative 5493\n",
      "firm 5486\n",
      "directed 5273\n",
      "grand 5237\n",
      "brutal 4709\n",
      "active 4700\n",
      "intense 4457\n",
      "selfish 4413\n",
      "insulting 3869\n",
      "tough 3854\n",
      "scheming 3693\n",
      "kind 3644\n",
      "disturbing 3628\n",
      "modern 3562\n",
      "solitary 3540\n",
      "simple 3426\n",
      "dishonest 3374\n",
      "solid 3337\n",
      "ruined 3229\n",
      "religious 3205\n",
      "proud 3193\n",
      "naive 3174\n",
      "authoritarian 3106\n",
      "crazy 3030\n",
      "angry 3001\n",
      "soft 2970\n",
      "popular 2560\n",
      "independent 2320\n",
      "pompous 2312\n",
      "weak 2263\n",
      "busy 2173\n",
      "questioning 2136\n",
      "tolerant 1989\n",
      "obvious 1958\n",
      "progressive 1943\n",
      "bizarre 1925\n",
      "pure 1787\n",
      "careless 1684\n",
      "narrow 1650\n",
      "intolerant 1614\n",
      "brilliant 1611\n",
      "demanding 1498\n",
      "hateful 1476\n",
      "sweet 1388\n",
      "unhealthy 1378\n",
      "suspicious 1359\n",
      "critical 1305\n",
      "dramatic 1273\n",
      "extreme 1194\n",
      "skeptical 1185\n",
      "ridiculous 1179\n",
      "confused 1120\n",
      "steady 1089\n",
      "silly 1035\n",
      "peaceful 1005\n",
      "fair 983\n",
      "sharing 980\n",
      "capable 971\n",
      "sensitive 947\n",
      "objective 937\n",
      "original 862\n",
      "surprising 859\n",
      "knowledge 839\n",
      "driving 832\n",
      "deceitful 797\n",
      "enthusiastic 786\n",
      "irresponsible 746\n",
      "vulnerable 745\n",
      "stable 731\n",
      "hostile 727\n",
      "organized 723\n",
      "slow 715\n",
      "benevolent 711\n",
      "fixed 688\n",
      "caring 683\n",
      "outrageous 650\n",
      "sensual 641\n",
      "educated 620\n",
      "calm 607\n",
      "ambitious 602\n",
      "difficult 597\n",
      "patriotic 589\n",
      "curious 580\n",
      "thorough 554\n",
      "emotional 547\n",
      "unstable 525\n",
      "willful 504\n",
      "aggressive 503\n",
      "fiery 495\n",
      "shallow 490\n",
      "cute 482\n",
      "extraordinary 479\n",
      "dedicated 444\n",
      "understanding 439\n",
      "decent 431\n",
      "insecure 417\n",
      "respectful 397\n",
      "greedy 397\n",
      "sane 384\n",
      "cruel 383\n",
      "focused 382\n",
      "puritanical 381\n",
      "frightening 357\n",
      "lazy 354\n",
      "glamorous 339\n",
      "protective 338\n",
      "rational 331\n",
      "erratic 320\n",
      "sordid 310\n",
      "intelligent 302\n",
      "determined 302\n",
      "physical 299\n",
      "cautious 296\n",
      "healthy 295\n",
      "secretive 286\n",
      "mature 285\n",
      "passionate 281\n",
      "reliable 276\n",
      "callous 265\n",
      "foolish 265\n",
      "blunt 255\n",
      "confidential 249\n",
      "complex 247\n",
      "modest 243\n",
      "genuine 231\n",
      "airy 231\n",
      "morbid 231\n",
      "energetic 227\n",
      "profound 224\n",
      "pugnacious 223\n",
      "warm 222\n",
      "sexy 220\n",
      "deceptive 212\n",
      "hardworking 206\n",
      "obedient 204\n",
      "exciting 201\n",
      "sympathetic 199\n",
      "wise 196\n",
      "fraudulent 194\n",
      "impressive 187\n",
      "vindictive 187\n",
      "constant 186\n",
      "grim 186\n",
      "predictable 185\n",
      "predatory 184\n",
      "vague 182\n",
      "disciplined 176\n",
      "vivacious 173\n",
      "narcissistic 173\n",
      "neutral 170\n",
      "paranoid 158\n",
      "articulate 151\n",
      "cynical 150\n",
      "helpful 148\n",
      "moderate 144\n",
      "creative 138\n",
      "decisive 136\n",
      "gullible 132\n",
      "compulsive 131\n",
      "honorable 130\n",
      "witty 123\n",
      "artificial 121\n",
      "formal 120\n",
      "barbaric 119\n",
      "complacent 116\n",
      "optimistic 109\n",
      "challenging 108\n",
      "insightful 108\n",
      "stern 105\n",
      "invisible 103\n",
      "romantic 102\n",
      "logical 101\n",
      "gracious 100\n",
      "practical 98\n",
      "elegant 97\n",
      "devious 94\n",
      "sadistic 92\n",
      "faithful 91\n",
      "incisive 88\n",
      "petty 88\n",
      "balanced 81\n",
      "conventional 79\n",
      "outspoken 78\n",
      "gentle 76\n",
      "charming 75\n",
      "expedient 73\n",
      "steely 71\n",
      "subtle 70\n",
      "venal 70\n",
      "sophisticated 69\n",
      "venomous 68\n",
      "principled 67\n",
      "disrespectful 67\n",
      "cowardly 66\n",
      "calculating 65\n",
      "insincere 65\n",
      "amoral 64\n",
      "miserable 64\n",
      "patient 63\n",
      "casual 63\n",
      "extravagant 62\n",
      "ritualistic 61\n",
      "realistic 60\n",
      "dominating 56\n",
      "crude 56\n",
      "disruptive 56\n",
      "generous 55\n",
      "oppressed 55\n",
      "earnest 54\n",
      "courageous 53\n",
      "wishful 52\n",
      "retiring 51\n",
      "obnoxious 51\n",
      "eloquent 50\n",
      "neat 50\n",
      "attractive 49\n",
      "sarcastic 49\n",
      "compassionate 47\n",
      "moody 47\n",
      "mechanical 46\n",
      "treacherous 46\n",
      "competitive 45\n",
      "prudent 44\n",
      "reserved 43\n",
      "efficient 41\n",
      "unpatriotic 41\n",
      "gloomy 40\n",
      "dull 38\n",
      "sloppy 38\n",
      "anxious 37\n",
      "fearful 37\n",
      "sporting 36\n",
      "accessible 35\n",
      "innovative 35\n",
      "forgiving 34\n",
      "stubborn 34\n",
      "dependent 33\n",
      "irrational 33\n",
      "disloyal 32\n",
      "mistaken 30\n",
      "insensitive 28\n",
      "aspiring 27\n",
      "amusing 26\n",
      "crass 26\n",
      "messy 26\n",
      "hearty 25\n",
      "smooth 25\n",
      "prejudiced 25\n",
      "humorous 24\n",
      "misguided 24\n",
      "tense 24\n",
      "uncaring 24\n",
      "colorful 22\n",
      "dignified 22\n",
      "admirable 21\n",
      "dynamic 20\n",
      "clumsy 20\n",
      "opportunistic 20\n",
      "humble 19\n",
      "shrewd 19\n",
      "charismatic 18\n",
      "daring 18\n",
      "bland 18\n",
      "stiff 18\n",
      "assertive 17\n",
      "faithless 17\n",
      "prim 17\n",
      "provocative 17\n",
      "superstitious 17\n",
      "persuasive 16\n",
      "polished 16\n",
      "relaxed 16\n",
      "fawning 16\n",
      "perverse 16\n",
      "unfriendly 16\n",
      "systematic 15\n",
      "hesitant 15\n",
      "trendy 15\n",
      "unprincipled 15\n",
      "mellow 14\n",
      "delicate 14\n",
      "fanatical 14\n",
      "providential 13\n",
      "experimental 13\n",
      "strict 13\n",
      "discreet 12\n",
      "selfless 12\n",
      "effeminate 12\n",
      "upright 11\n",
      "malicious 11\n",
      "incorruptible 10\n",
      "sage 10\n",
      "crisp 10\n",
      "iconoclastic 10\n",
      "stylish 10\n",
      "frivolous 10\n",
      "monstrous 10\n",
      "presumptuous 10\n",
      "unreliable 10\n",
      "sentimental 9\n",
      "contradictory 9\n",
      "unfathomable 9\n",
      "envious 9\n",
      "forgetful 9\n",
      "rowdy 9\n",
      "troublesome 9\n",
      "lovable 8\n",
      "precise 8\n",
      "spontaneous 8\n",
      "apathetic 8\n",
      "unrealistic 8\n",
      "empathetic 7\n",
      "agonizing 7\n",
      "decadent 7\n",
      "discouraging 7\n",
      "quirky 7\n",
      "undisciplined 7\n",
      "idealistic 6\n",
      "preoccupied 6\n",
      "restrained 6\n",
      "aloof 6\n",
      "contemptible 6\n",
      "haughty 6\n",
      "neurotic 6\n",
      "obsessive 6\n",
      "pretentious 6\n",
      "submissive 6\n",
      "thoughtless 6\n"
     ]
    }
   ],
   "source": [
    "# min_count in W2V is 5\n",
    "dlist = [s for s in dlist if s[1] > 5]\n",
    "\n",
    "print(target_word)\n",
    "for i in dlist:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding model\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences, size=100, window=5, min_count=3, workers=4)\n",
    "model.train(sentences, total_examples=len(sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "def top_adjectives(model, token, topn=10):\n",
    "    out = []\n",
    "    word_to_sim = {}\n",
    "    same = []\n",
    "    for elem in dlist:\n",
    "        if elem[0] == token:\n",
    "            same = elem\n",
    "    if same != []:\n",
    "        unique_dlist = dlist[:]\n",
    "        unique_dlist.remove(same)\n",
    "    else:\n",
    "        unique_dlist = dlist[:]\n",
    "    for wo in unique_dlist:\n",
    "        w = wo[0]\n",
    "        word, similarity = w, model.wv.similarity(w1=token,w2=w)\n",
    "        if len(out) < topn:\n",
    "            bisect.insort(out, similarity)\n",
    "            word_to_sim[similarity] = word \n",
    "        if similarity > out[0] and len(out) == topn and word not in word_to_sim.values():\n",
    "            del out[0]\n",
    "            bisect.insort(out, similarity)\n",
    "            word_to_sim[similarity] = word\n",
    "            \n",
    "    adj_order = []\n",
    "    for sim in out:\n",
    "        adj_order.append([word_to_sim[sim], sim])\n",
    "    adj_order.append([token, ''])\n",
    "    return adj_order[::-1]\n",
    "\n",
    "res = top_adjectives\n",
    "for elem in top_adjectives(model, target_word):\n",
    "    print(elem[0], elem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(model, token, topn=10):\n",
    "    base = top_adjectives(model, token, topn)\n",
    "    network = []\n",
    "    network.append([base])\n",
    "    for i in range(topn-1, 0, -1):\n",
    "        new_related = top_adjectives(model, base[topn - i][0])\n",
    "        network.append([new_related, [[0]], [[topn - i]]])\n",
    "\n",
    "        for layer in range(topn-1, 0, -1):\n",
    "            layered_related = top_adjectives(model, new_related[topn - layer][0])\n",
    "            network.append([layered_related, [[topn - layer + 1]], [[topn - i]]])\n",
    "    return network\n",
    "\n",
    "net = network(model, target_word)\n",
    "def print_network(net):\n",
    "    for words in net:\n",
    "        for items in words: \n",
    "            for word in items:\n",
    "                if len(word) == 2:\n",
    "                    print(word[0], word[1])\n",
    "                else:\n",
    "                    print(word[0])\n",
    "        print('\\n')\n",
    "\n",
    "print_network(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
